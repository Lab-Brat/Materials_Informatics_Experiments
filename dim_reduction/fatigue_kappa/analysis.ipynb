{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Materials Fatigues data has the shape:  (437, 16) and (437,)\nThermal Conductance data has the shape: (320, 36) and (320,)\n"
     ]
    }
   ],
   "source": [
    "# read MATERIALS FATIGUE data from csv file\n",
    "dataf = pd.read_csv('fatigue_data.csv', index_col='Sl. No.')\n",
    "\n",
    "# set X as columns C, Ni, Cr and Mo (No.16-19)\n",
    "Xf = dataf.drop(dataf.columns[16:20], axis=1) \n",
    "# set y as 'Fatigue' column (No.17)\n",
    "yf = dataf['Fatigue']\n",
    "\n",
    "\n",
    "# read THERMAL CONDUCTANCE data from xlsx file\n",
    "datak = pd.read_excel('kappa.xlsx')\n",
    "\n",
    "Xk = datak.drop(datak.columns[0:3], axis=1).drop(datak.columns[-1], axis=1)\n",
    "yk = datak[datak.columns[-1]]\n",
    "\n",
    "\n",
    "# Output shapes\n",
    "print(\"Materials Fatigues data has the shape:  {0} and {1}\".format(Xf.shape, yf.shape))\n",
    "print(\"Thermal Conductance data has the shape: {0} and {1}\".format(Xk.shape, yk.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VT result for Material Fatigue\n(437, 10)\n\n\nVT result for Kappa\n(320, 12)\n"
     ]
    }
   ],
   "source": [
    "thresholder = VarianceThreshold(threshold=100)\n",
    "print(\"VT result for Material Fatigue\")\n",
    "Xf_features_high_variance = thresholder.fit_transform(Xf)\n",
    "print(Xf_features_high_variance.shape)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "thresholder = VarianceThreshold(threshold=100)\n",
    "print(\"VT result for Kappa\")\n",
    "Xk_features_high_variance = thresholder.fit_transform(Xk)\n",
    "print(Xk_features_high_variance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "features=[[0,1,0],\n",
    "          [0,1,1],\n",
    "          [0,1,0],\n",
    "          [0,1,1],\n",
    "          [1,0,0]]\n",
    "\n",
    "thresholder = VarianceThreshold(0.75 * (1 - 0.75))\n",
    "features_high_variance = thresholder.fit_transform(features)\n",
    "features_high_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.16, 0.16, 0.24])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "thresholder.fit(features).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VT result for Material Fatigue\n(437, 14)\n\n\n"
     ]
    }
   ],
   "source": [
    "thresholder = VarianceThreshold(threshold=.9 * (1 - .9))\n",
    "print(\"VT result for Material Fatigue\")\n",
    "Xf_features_high_variance = thresholder.fit_transform(Xf)\n",
    "print(Xf_features_high_variance.shape)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variance of Fatugue Data\n[6.85500526e+02 7.82410122e+04 1.05105017e+02 6.13474229e+01\n 7.91977756e+04 1.60730141e+04 7.11945768e+04 2.45928321e+02\n 3.76245359e+02 2.68678309e+04 4.60233860e+02 6.50114102e+01\n 9.26471103e-03 7.25902728e-01 1.69165923e-01 7.74801250e-03]\n\n\nVariance of Kappa Data\n[2.47646484e-01 5.31839844e+00 4.78655859e+01 1.54351715e+03\n 8.37815954e-01 8.31401508e-01 1.95799691e+00 1.53808594e+02\n 1.53808594e+02 4.74750000e+02 3.54020194e+00 3.18413379e+03\n 2.47495301e+02 3.36530771e+00 8.63942685e+01 4.14071787e+02\n 1.54032412e+02 1.70491485e+02 1.58746484e-01 1.16105371e-01\n 6.09313283e-02 1.15121094e+00 1.05389648e+00 6.35691904e-01\n 7.19996094e+00 1.45183496e+01 8.33767374e+00 2.86790430e+03\n 8.70593332e+02 1.09367015e+03 6.54301277e-01 2.10370207e-01\n 2.16011763e-01 4.19964840e-01 1.22278827e-01 1.33775910e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Variance of Fatugue Data\")\n",
    "print(thresholder.fit(Xf).variances_)\n",
    "print('\\n')\n",
    "\n",
    "print(\"Variance of Kappa Data\")\n",
    "print(thresholder.fit(Xk).variances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xf_std = scaler.fit_transform(Xf)\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "\n",
    "# output 1 means that feature noramlization is scuccessful\n",
    "selector.fit(Xf_std).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xk_std = scaler.fit_transform(Xk)\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "\n",
    "# output 1 means that feature noramlization is scuccessful\n",
    "selector.fit(Xk_std).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Before Scaling\nMaxes: 389.634915603905\nMins: -82.56689644\n\n\nAfter Scaling\nMaxes: 6.539535537180673\nMins: -5.476052162160264\n"
     ]
    }
   ],
   "source": [
    "MAX_b = []\n",
    "MIN_b = []\n",
    "\n",
    "for j in range(len(Xk.columns)):\n",
    "    MAX_b.append(Xk[Xk.columns[j]].max())\n",
    "    MIN_b.append(Xk[Xk.columns[j]].min())\n",
    "\n",
    "\n",
    "print(\"Before Scaling\")\n",
    "print(\"Maxes: {}\".format(max(MAX_b)))\n",
    "print(\"Mins: {}\".format(min(MIN_b)))\n",
    "\n",
    "\n",
    "MAX_a = []\n",
    "MIN_a = []\n",
    "\n",
    "for i in range(len(Xk_std)):\n",
    "    MAX_a.append(max(Xk_std[i]))\n",
    "    MIN_a.append(min(Xk_std[i]))\n",
    "\n",
    "print('\\n')\n",
    "print(\"After Scaling\")\n",
    "print(\"Maxes: {}\".format(max(MAX_a)))\n",
    "print(\"Mins: {}\".format(min(MIN_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results for Materials Fatigue\n",
      "Number of chosen features 5, eliminated features 11,\n",
      "feature rankings [ 7  6  3  5  2 12  9 11 10  8  1  4  1  1  1  1] \n",
      "\n",
      "\n",
      "Results for Thermal Conductance\n",
      "Number of chosen features 29, eliminated features 7,\n",
      "feature rankings [1 5 4 7 1 1 1 1 1 1 1 8 6 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 3 1 1 1 1] \n"
     ]
    }
   ],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "rfecv.fit(Xf, yf)\n",
    "rfecv.transform(Xf)\n",
    "C = rfecv.n_features_\n",
    "D = Xf.shape[1] - C\n",
    "R = rfecv.ranking_\n",
    "print(\"Results for Materials Fatigue\")\n",
    "print(\"Number of chosen features {0}, eliminated features {1},\\nfeature rankings {2} \".format(C, D, R))\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "rfecv.fit(Xk, yk)\n",
    "rfecv.transform(Xk)\n",
    "C = rfecv.n_features_\n",
    "D = Xk.shape[1] - C\n",
    "R = rfecv.ranking_\n",
    "print('\\n')\n",
    "print(\"Results for Thermal Conductance\")\n",
    "print(\"Number of chosen features {0}, eliminated features {1},\\nfeature rankings {2} \".format(C, D, R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Materials Fatigue\nOriginal number of features: 16\nReduced number of features: 3\n\n\nThermal Conductance\nOriginal number of features: 36\nReduced number of features: 3\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3, whiten=True)\n",
    "\n",
    "# compute principal components\n",
    "Xf_pca = pca.fit_transform(Xf)\n",
    "Xk_pca = pca.fit_transform(Xk)\n",
    "\n",
    "print(\"Materials Fatigue\")\n",
    "print(\"Original number of features:\", Xf.shape[1])\n",
    "print(\"Number of features after reduction:\", Xf_pca.shape[1])\n",
    "\n",
    "print('\\n')\n",
    "print(\"Thermal Conductance\")\n",
    "print(\"Original number of features:\", Xk.shape[1])\n",
    "print(\"Number of features after reduction:\", Xk_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     principal component 1  principal component 2  Fatigue\n",
       "0                 0.815845               5.997737      232\n",
       "1                 0.815845               5.997736      235\n",
       "2                 0.815845               5.997737      235\n",
       "3                 0.815845               5.997737      241\n",
       "4                 0.815845               5.997737      225\n",
       "..                     ...                    ...      ...\n",
       "432               2.802381              -0.496030     1030\n",
       "433               2.802381              -0.496031      957\n",
       "434               2.774571              -0.647919     1104\n",
       "435               2.774571              -0.647917     1008\n",
       "436               2.774571              -0.647919      882\n",
       "\n",
       "[437 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>principal component 1</th>\n      <th>principal component 2</th>\n      <th>Fatigue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.815845</td>\n      <td>5.997737</td>\n      <td>232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.815845</td>\n      <td>5.997736</td>\n      <td>235</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.815845</td>\n      <td>5.997737</td>\n      <td>235</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.815845</td>\n      <td>5.997737</td>\n      <td>241</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.815845</td>\n      <td>5.997737</td>\n      <td>225</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>2.802381</td>\n      <td>-0.496030</td>\n      <td>1030</td>\n    </tr>\n    <tr>\n      <th>433</th>\n      <td>2.802381</td>\n      <td>-0.496031</td>\n      <td>957</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>2.774571</td>\n      <td>-0.647919</td>\n      <td>1104</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>2.774571</td>\n      <td>-0.647917</td>\n      <td>1008</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>2.774571</td>\n      <td>-0.647919</td>\n      <td>882</td>\n    </tr>\n  </tbody>\n</table>\n<p>437 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "dataf = pd.read_csv('fatigue_data.csv')\n",
    "\n",
    "principalComponents = pca.fit_transform(Xf)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, dataf[['Fatigue']]], axis = 1)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Linear Discriminant analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=5)\n",
    "Xf_lda = lda.fit(Xf,yf).transform(Xf)\n",
    "\n",
    "print(\"Original number of features:\", Xf.shape[1])\n",
    "print(\"Reduced number of features:\", Xf_lda.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}