{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((437, 16), (437,))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# read date from csv file\n",
    "data = pd.read_csv('fatigue_data.csv', index_col='Sl. No.')\n",
    "\n",
    "# set X as columns C, Ni, Cr and Mo (No.16-19)\n",
    "Xf = data.drop(data.columns[16:20], axis=1) \n",
    "# set y as 'Fatigue' column (No.17)\n",
    "yf = data['Fatigue']\n",
    "\n",
    "Xf.shape, yf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((320, 36), (320,))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# read date from xlsx file\n",
    "data = pd.read_excel('kappa.xlsx')\n",
    "\n",
    "Xk = data.drop(data.columns[0:3], axis=1).drop(data.columns[-1], axis=1)\n",
    "yk = data[data.columns[-1]]\n",
    "\n",
    "Xk.shape, yk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[885.,  30.,   0., ...,  30.,  30.,   0.],\n",
       "       [885.,  30.,   0., ...,  30.,  30.,   0.],\n",
       "       [885.,  30.,   0., ...,  30.,  30.,   0.],\n",
       "       ...,\n",
       "       [930.,  30.,   0., ...,  60., 200., 120.],\n",
       "       [930.,  30.,   0., ...,  60., 200., 120.],\n",
       "       [930.,  30.,   0., ...,  60., 200., 120.]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "thresholder = VarianceThreshold(threshold=100)\n",
    "features_high_variance = thresholder.fit_transform(Xf)\n",
    "\n",
    "features_high_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([6.85500526e+02, 7.82410122e+04, 1.05105017e+02, 6.13474229e+01,\n",
       "       7.91977756e+04, 1.60730141e+04, 7.11945768e+04, 2.45928321e+02,\n",
       "       3.76245359e+02, 2.68678309e+04, 4.60233860e+02, 6.50114102e+01,\n",
       "       9.26471103e-03, 7.25902728e-01, 1.69165923e-01, 7.74801250e-03])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "thresholder.fit(Xf).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "Xf_std = scaler.fit_transform(Xf)\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "\n",
    "# output 1 means that feature noramlization is scuccessful\n",
    "selector.fit(Xf_std).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.00e+00, 2.60e-01, 1.00e-02, 2.00e-02, 0.00e+00],\n",
       "       [0.00e+00, 2.50e-01, 8.00e-02, 1.20e-01, 0.00e+00],\n",
       "       [0.00e+00, 2.60e-01, 2.00e-02, 3.00e-02, 0.00e+00],\n",
       "       ...,\n",
       "       [1.20e+02, 2.10e-01, 6.00e-02, 1.17e+00, 1.70e-01],\n",
       "       [1.20e+02, 2.10e-01, 2.00e-02, 9.10e-01, 1.50e-01],\n",
       "       [1.20e+02, 1.80e-01, 7.00e-02, 1.08e+00, 1.50e-01]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "rfecv = RFECV(estimator=ols,step=1,scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "rfecv.fit(Xf, yf)\n",
    "rfecv.transform(Xf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5,\n",
       " array([False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False,  True,  True,  True,  True]),\n",
       " array([ 7,  6,  3,  5,  2, 12,  9, 11, 10,  8,  1,  4,  1,  1,  1,  1]))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "rfecv.n_features_, rfecv.support_, rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original number of features: 16\nReduced number of features: 3\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.99, whiten=True)\n",
    "Xf_pca = pca.fit_transform(Xf)\n",
    "\n",
    "print(\"Original number of features:\", Xf.shape[1])\n",
    "print(\"Reduced number of features:\", Xf_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Kernel \n",
    "from sklearn.decomposition import PCA, KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original number of features: 16\nReduced number of features: 1\n"
     ]
    }
   ],
   "source": [
    "kpca = KernelPCA(kernel=\"rbf\",gamma=15,n_components=1)\n",
    "Xf_kpca = kpca.fit_transform(Xf)\n",
    "\n",
    "print(\"Original number of features:\",Xf.shape[1])\n",
    "print(\"Reduced number of features:\",Xf_kpca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Linear Discriminant analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original number of features: 16\nReduced number of features: 5\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=5)\n",
    "Xf_lda = lda.fit(Xf,yf).transform(Xf)\n",
    "\n",
    "print(\"Original number of features:\", Xf.shape[1])\n",
    "print(\"Reduced number of features:\", Xf_lda.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-negative matrix factorization\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original number of features: 16\nReduced number of features: 10\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=10,random_state=1)\n",
    "Xf_nmf = nmf.fit_transform(Xf)\n",
    "\n",
    "print(\"Original number of features:\", Xf.shape[1])\n",
    "print(\"Reduced number of features:\", Xf_nmf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}